{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFQm2L/AY8loR7Sdp3bJQ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pritip22/DSA_LAB/blob/main/AIDS2_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uploading of Data Set anf checking for Null Values\n"
      ],
      "metadata": {
        "id": "wmFji_G9674Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0BGPwB-a6A6q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/dairy_dataset.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing data\n",
        "print(data.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUvW2R-J6SZ-",
        "outputId": "94ea4571-37df-4287-84b2-d5ef09ffcdf6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Location                               0\n",
            "Total Land Area (acres)                0\n",
            "Number of Cows                         0\n",
            "Farm Size                              0\n",
            "Date                                   0\n",
            "Product ID                             0\n",
            "Product Name                           0\n",
            "Brand                                  0\n",
            "Quantity (liters/kg)                   0\n",
            "Price per Unit                         0\n",
            "Total Value                            0\n",
            "Shelf Life (days)                      0\n",
            "Storage Condition                      0\n",
            "Production Date                        0\n",
            "Expiration Date                        0\n",
            "Quantity Sold (liters/kg)              0\n",
            "Price per Unit (sold)                  0\n",
            "Approx. Total Revenue(INR)             0\n",
            "Customer Location                      0\n",
            "Sales Channel                          0\n",
            "Quantity in Stock (liters/kg)          0\n",
            "Minimum Stock Threshold (liters/kg)    0\n",
            "Reorder Quantity (liters/kg)           0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.fillna(method='ffill', inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo29LY4k6syk",
        "outputId": "a3338419-1283-421e-cc11-240aea923dbf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-519281724d28>:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data.fillna(method='ffill', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Selection"
      ],
      "metadata": {
        "id": "Adk9BOyP7OEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\n",
        "    'Location', 'Total Land Area (acres)', 'Number of Cows', 'Farm Size',\n",
        "    'Date', 'Product Name', 'Brand', 'Quantity (liters/kg)', 'Price per Unit',\n",
        "    'Production Date', 'Expiration Date', 'Sales Channel',\n",
        "    'Quantity in Stock (liters/kg)', 'Minimum Stock Threshold (liters/kg)'\n",
        "]\n",
        "\n",
        "target = 'Quantity Sold (liters/kg)'\n"
      ],
      "metadata": {
        "id": "UnLjVvf86Vgf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering: Transformation of Data and Encoding Categorial Variables\n"
      ],
      "metadata": {
        "id": "umNsx_2y7WB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Convert dates to numerical values\n",
        "data['Date'] = pd.to_datetime(data['Date']).astype(int) / 10**9  # Convert date to seconds\n",
        "data['Production Date'] = pd.to_datetime(data['Production Date']).astype(int) / 10**9\n",
        "data['Expiration Date'] = pd.to_datetime(data['Expiration Date']).astype(int) / 10**9\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "data['Location'] = label_encoder.fit_transform(data['Location'])\n",
        "data['Product Name'] = label_encoder.fit_transform(data['Product Name'])\n",
        "data['Brand'] = label_encoder.fit_transform(data['Brand'])\n",
        "data['Sales Channel'] = label_encoder.fit_transform(data['Sales Channel'])\n",
        "data['Farm Size'] = label_encoder.fit_transform(data['Farm Size'])\n"
      ],
      "metadata": {
        "id": "GFruyFk17Q4K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Normalization"
      ],
      "metadata": {
        "id": "-tZzDhpz7hfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data[features])\n"
      ],
      "metadata": {
        "id": "DqMIGUdh7drX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting Data for Training and Testing"
      ],
      "metadata": {
        "id": "dUmZIZEG7qWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = scaled_data  # Feature set\n",
        "y = data[target].values  # Target (Quantity Sold)\n",
        "\n",
        "# Split into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "Jmweil_27k5-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the Neural Network Model (Using FeedForward Neural Network)"
      ],
      "metadata": {
        "id": "hcalsBVp727i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer (number of input features)\n",
        "model.add(Dense(units=128, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "\n",
        "# Add hidden layers\n",
        "model.add(Dense(units=64, activation='relu'))\n",
        "model.add(Dense(units=32, activation='relu'))\n",
        "\n",
        "# Add output layer (since we are predicting a continuous value)\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bA421Cc7y1X",
        "outputId": "55b6c4c0-c3ad-4201-aff7-c22d58b662a8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 104781.4531 - val_loss: 50682.3867\n",
            "Epoch 2/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 44994.7383 - val_loss: 45940.0898\n",
            "Epoch 3/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 45217.3984 - val_loss: 40798.4688\n",
            "Epoch 4/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 36661.8242 - val_loss: 31988.9688\n",
            "Epoch 5/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27686.7480 - val_loss: 14908.0898\n",
            "Epoch 6/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9904.9004 - val_loss: 1558.2637\n",
            "Epoch 7/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 861.2340 - val_loss: 125.6844\n",
            "Epoch 8/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 97.9389 - val_loss: 44.5292\n",
            "Epoch 9/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 33.5822 - val_loss: 20.0253\n",
            "Epoch 10/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 16.2435 - val_loss: 13.5730\n",
            "Epoch 11/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 12.4005 - val_loss: 10.8120\n",
            "Epoch 12/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.6711 - val_loss: 9.2840\n",
            "Epoch 13/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8267 - val_loss: 9.8657\n",
            "Epoch 14/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.9815 - val_loss: 7.5126\n",
            "Epoch 15/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9256 - val_loss: 7.0565\n",
            "Epoch 16/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.4359 - val_loss: 6.1572\n",
            "Epoch 17/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 5.9277 - val_loss: 5.8290\n",
            "Epoch 18/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 5.4876 - val_loss: 6.3703\n",
            "Epoch 19/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3051 - val_loss: 4.5697\n",
            "Epoch 20/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 4.0961 - val_loss: 4.7858\n",
            "Epoch 21/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.9167 - val_loss: 3.9991\n",
            "Epoch 22/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.9207 - val_loss: 4.7412\n",
            "Epoch 23/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 3.3570 - val_loss: 3.6081\n",
            "Epoch 24/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8582 - val_loss: 3.3105\n",
            "Epoch 25/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0215 - val_loss: 3.2282\n",
            "Epoch 26/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.5097 - val_loss: 3.4600\n",
            "Epoch 27/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.6696 - val_loss: 3.1136\n",
            "Epoch 28/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.2973 - val_loss: 3.0778\n",
            "Epoch 29/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 2.1405 - val_loss: 2.4903\n",
            "Epoch 30/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.9956 - val_loss: 3.1976\n",
            "Epoch 31/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7969 - val_loss: 2.2674\n",
            "Epoch 32/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7965 - val_loss: 2.0837\n",
            "Epoch 33/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5250 - val_loss: 1.8738\n",
            "Epoch 34/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.7145 - val_loss: 1.8073\n",
            "Epoch 35/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5798 - val_loss: 1.8911\n",
            "Epoch 36/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4855 - val_loss: 1.8807\n",
            "Epoch 37/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.4157 - val_loss: 1.7632\n",
            "Epoch 38/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1040 - val_loss: 1.9540\n",
            "Epoch 39/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1204 - val_loss: 1.8494\n",
            "Epoch 40/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1.1312 - val_loss: 1.3978\n",
            "Epoch 41/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0478 - val_loss: 1.6041\n",
            "Epoch 42/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0675 - val_loss: 1.4286\n",
            "Epoch 43/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9468 - val_loss: 2.1745\n",
            "Epoch 44/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.1030 - val_loss: 1.3451\n",
            "Epoch 45/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8605 - val_loss: 1.0768\n",
            "Epoch 46/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7900 - val_loss: 1.0151\n",
            "Epoch 47/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8545 - val_loss: 1.0786\n",
            "Epoch 48/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.8953 - val_loss: 1.2417\n",
            "Epoch 49/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7414 - val_loss: 1.0173\n",
            "Epoch 50/50\n",
            "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8598 - val_loss: 0.9101\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fb8c0a585e0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "534rUsyHBoc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "print(f'Mean Absolute Error: {mae}')\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "print(f'Root Mean Squared Error: {rmse}')\n",
        "\n",
        "# Calculate R-squared (Testing Accuracy)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R-squared (Testing Accuracy): {r2}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VgUCHwD_OOK",
        "outputId": "74e2b146-1d21-4476-da59-0505992bda04"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Mean Absolute Error: 0.5337569003763226\n",
            "Root Mean Squared Error: 0.8144472683318962\n",
            "R-squared (Testing Accuracy): 0.99998539686203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Deployment and Building a predictive system\n"
      ],
      "metadata": {
        "id": "io2OYSnOEVLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "\n",
        "# Assuming 'model' is already trained\n",
        "\n",
        "# Re-use the dataset or the list of unique values seen during training\n",
        "# Here's an example of how to extend the label encoding with unseen labels\n",
        "possible_locations = ['Telangana', 'Mumbai', 'Karnataka', 'Andhra Pradesh']  # Add any other locations\n",
        "possible_products = ['Ice Cream', 'Milk', 'Yogurt']  # Example of products, extend as necessary\n",
        "possible_brands = ['Dodla Dairy', 'Amul', 'Nandini']  # Add brands seen during training\n",
        "possible_sales_channels = ['Wholesale', 'Retail']  # Sales channels seen during training\n",
        "possible_farm_sizes = ['Small', 'Medium', 'Large']\n",
        "\n",
        "# Re-train label encoders with all possible categories\n",
        "label_encoder_location = LabelEncoder()\n",
        "label_encoder_location.fit(possible_locations)\n",
        "\n",
        "label_encoder_product = LabelEncoder()\n",
        "label_encoder_product.fit(possible_products)\n",
        "\n",
        "label_encoder_brand = LabelEncoder()\n",
        "label_encoder_brand.fit(possible_brands)\n",
        "\n",
        "label_encoder_sales_channel = LabelEncoder()\n",
        "label_encoder_sales_channel.fit(possible_sales_channels)\n",
        "\n",
        "label_encoder_farm_size = LabelEncoder()\n",
        "label_encoder_farm_size.fit(possible_farm_sizes)\n",
        "\n",
        "# Prediction function\n",
        "def make_prediction(input_data):\n",
        "    # Convert input data to a DataFrame\n",
        "    input_df = pd.DataFrame([input_data])\n",
        "\n",
        "    # Convert date columns to timestamps\n",
        "    input_df['Date'] = pd.to_datetime(input_df['Date']).astype(int) / 10**9\n",
        "    input_df['Production Date'] = pd.to_datetime(input_df['Production Date']).astype(int) / 10**9\n",
        "    input_df['Expiration Date'] = pd.to_datetime(input_df['Expiration Date']).astype(int) / 10**9\n",
        "\n",
        "    # Label encoding (make sure unseen labels are handled properly)\n",
        "    input_df['Location'] = label_encoder_location.transform(input_df['Location'])\n",
        "    input_df['Product Name'] = label_encoder_product.transform(input_df['Product Name'])\n",
        "    input_df['Brand'] = label_encoder_brand.transform(input_df['Brand'])\n",
        "    input_df['Sales Channel'] = label_encoder_sales_channel.transform(input_df['Sales Channel'])\n",
        "    input_df['Farm Size'] = label_encoder_farm_size.transform(input_df['Farm Size'])\n",
        "\n",
        "    # Scale the input data\n",
        "    input_scaled = scaler.transform(input_df[features])\n",
        "\n",
        "    # Make the prediction using the recently trained model\n",
        "    prediction = model.predict(input_scaled)\n",
        "    return prediction[0][0]\n",
        "\n",
        "# Sample input for prediction (you can modify this as needed)\n",
        "sample_input = {\n",
        "    \"Location\": \"Mumbai\",\n",
        "    \"Total Land Area (acres)\": 310.84,\n",
        "    \"Number of Cows\": 96,\n",
        "    \"Farm Size\": \"Medium\",\n",
        "    \"Date\": \"2022-02-17\",\n",
        "    \"Product Name\": \"Ice Cream\",\n",
        "    \"Brand\": \"Dodla Dairy\",\n",
        "    \"Quantity (liters/kg)\": 222.40,\n",
        "    \"Price per Unit\": 85.72,\n",
        "    \"Production Date\": \"2021-12-27\",\n",
        "    \"Expiration Date\": \"2022-01-21\",\n",
        "    \"Sales Channel\": \"Wholesale\",\n",
        "    \"Quantity in Stock (liters/kg)\": 215,\n",
        "    \"Minimum Stock Threshold (liters/kg)\": 19.55\n",
        "}\n",
        "\n",
        "# Predict the output using the model that was just trained\n",
        "predicted_quantity_sold = make_prediction(sample_input)\n",
        "print(f'Predicted Quantity Sold: {predicted_quantity_sold:.2f} liters/kg')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3MX2X95sU8C",
        "outputId": "af10e05f-287e-464f-f886-57846d59ade8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "Predicted Quantity Sold: 6.90 liters/kg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0l7DL1LjthhV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}